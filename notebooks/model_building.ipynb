{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building\n",
    "\n",
    "In this notebook, we will build and evaluate machine learning models to predict customer churn. We will start by splitting the data into training and testing sets, followed by training various models, evaluating their performance, and selecting the best model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the preprocessed dataset\n",
    "data_path = \"../data/processed/cleaned_data.csv\"\n",
    "df = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test Split\n",
    "\n",
    "We split the dataset into training and testing sets to evaluate the performance of our models on unseen data. This step is crucial for estimating the generalization ability of our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target variable\n",
    "X = df.drop(columns=['customerID', 'Churn'])\n",
    "y = df['Churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: (5634, 19)\n",
      "Testing set size: (1409, 19)\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(\"Training set size:\", X_train.shape)\n",
    "print(\"Testing set size:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training and Evaluation\n",
    "\n",
    "We train several machine learning models and evaluate their performance using appropriate metrics. We aim to select the model that performs best on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42),\n",
    "    'Support Vector Machine': SVC(random_state=42)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate model performance\n",
    "def evaluate_model(model, X_train, y_train, X_test, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    return accuracy, precision, recall, f1, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store evaluation results\n",
    "evaluation_results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate each model\n",
    "for model_name, model in models.items():\n",
    "    accuracy, precision, recall, f1, y_pred = evaluate_model(model, X_train, y_train, X_test, y_test)\n",
    "    evaluation_results[model_name] = {\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1,\n",
    "        'Confusion Matrix': confusion_matrix(y_test, y_pred)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression Results:\n",
      "Accuracy: 0.8176\n",
      "Precision: 0.6824\n",
      "Recall: 0.5818\n",
      "F1 Score: 0.6281\n",
      "Confusion Matrix:\n",
      "[[935 101]\n",
      " [156 217]]\n",
      "\n",
      "Decision Tree Results:\n",
      "Accuracy: 0.7246\n",
      "Precision: 0.4809\n",
      "Recall: 0.5067\n",
      "F1 Score: 0.4935\n",
      "Confusion Matrix:\n",
      "[[832 204]\n",
      " [184 189]]\n",
      "\n",
      "Random Forest Results:\n",
      "Accuracy: 0.7970\n",
      "Precision: 0.6629\n",
      "Recall: 0.4745\n",
      "F1 Score: 0.5531\n",
      "Confusion Matrix:\n",
      "[[946  90]\n",
      " [196 177]]\n",
      "\n",
      "Support Vector Machine Results:\n",
      "Accuracy: 0.8112\n",
      "Precision: 0.6945\n",
      "Recall: 0.5121\n",
      "F1 Score: 0.5895\n",
      "Confusion Matrix:\n",
      "[[952  84]\n",
      " [182 191]]\n"
     ]
    }
   ],
   "source": [
    "# Display evaluation results\n",
    "for model_name, metrics in evaluation_results.items():\n",
    "    print(f\"\\n{model_name} Results:\")\n",
    "    print(f\"Accuracy: {metrics['Accuracy']:.4f}\")\n",
    "    print(f\"Precision: {metrics['Precision']:.4f}\")\n",
    "    print(f\"Recall: {metrics['Recall']:.4f}\")\n",
    "    print(f\"F1 Score: {metrics['F1 Score']:.4f}\")\n",
    "    print(f\"Confusion Matrix:\\n{metrics['Confusion Matrix']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning for Logistic Regression\n",
    "\n",
    "We perform hyperparameter tuning to optimize the performance of the Logistic Regression model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for Logistic Regression: {'C': 0.1, 'solver': 'saga'}\n",
      "Best Cross-Validation Accuracy for Logistic Regression: 0.7999648542713093\n"
     ]
    }
   ],
   "source": [
    "# Define parameter grid for Logistic Regression\n",
    "param_grid_lr = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'solver': ['liblinear', 'saga']\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV for Logistic Regression\n",
    "grid_search_lr = GridSearchCV(LogisticRegression(max_iter=1000, random_state=42), param_grid_lr, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Perform Grid Search for Logistic Regression\n",
    "grid_search_lr.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and best score for Logistic Regression\n",
    "best_params_lr = grid_search_lr.best_params_\n",
    "best_score_lr = grid_search_lr.best_score_\n",
    "\n",
    "print(\"Best Parameters for Logistic Regression:\", best_params_lr)\n",
    "print(\"Best Cross-Validation Accuracy for Logistic Regression:\", best_score_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning for Support Vector Machine\n",
    "\n",
    "We perform hyperparameter tuning to optimize the performance of the Support Vector Machine (SVM) model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for SVM: {'C': 1, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "Best Cross-Validation Accuracy for SVM: 0.7933971735269132\n"
     ]
    }
   ],
   "source": [
    "# Define parameter grid for SVM\n",
    "param_grid_svm = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': ['scale', 'auto'],\n",
    "    'kernel': ['linear', 'rbf']\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV for SVM\n",
    "grid_search_svm = GridSearchCV(SVC(random_state=42), param_grid_svm, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Perform Grid Search for SVM\n",
    "grid_search_svm.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and best score for SVM\n",
    "best_params_svm = grid_search_svm.best_params_\n",
    "best_score_svm = grid_search_svm.best_score_\n",
    "\n",
    "print(\"Best Parameters for SVM:\", best_params_svm)\n",
    "print(\"Best Cross-Validation Accuracy for SVM:\", best_score_svm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Model Evaluation\n",
    "\n",
    "We evaluate the final models on the test set to estimate their performance on unseen data. This step provides an unbiased estimate of the models' accuracy and generalization ability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Logistic Regression Model Results:\n",
      "Accuracy: 0.8204\n",
      "Precision: 0.6911\n",
      "Recall: 0.5818\n",
      "F1 Score: 0.6317\n",
      "Confusion Matrix:\n",
      "[[939  97]\n",
      " [156 217]]\n"
     ]
    }
   ],
   "source": [
    "# Train final Logistic Regression model with best parameters\n",
    "final_model_lr = LogisticRegression(**best_params_lr, max_iter=1000, random_state=42)\n",
    "final_model_lr.fit(X_train, y_train)\n",
    "y_pred_final_lr = final_model_lr.predict(X_test)\n",
    "\n",
    "# Evaluate final Logistic Regression model\n",
    "final_accuracy_lr = accuracy_score(y_test, y_pred_final_lr)\n",
    "final_precision_lr = precision_score(y_test, y_pred_final_lr)\n",
    "final_recall_lr = recall_score(y_test, y_pred_final_lr)\n",
    "final_f1_lr = f1_score(y_test, y_pred_final_lr)\n",
    "final_confusion_matrix_lr = confusion_matrix(y_test, y_pred_final_lr)\n",
    "\n",
    "print(\"\\nFinal Logistic Regression Model Results:\")\n",
    "print(f\"Accuracy: {final_accuracy_lr:.4f}\")\n",
    "print(f\"Precision: {final_precision_lr:.4f}\")\n",
    "print(f\"Recall: {final_recall_lr:.4f}\")\n",
    "print(f\"F1 Score: {final_f1_lr:.4f}\")\n",
    "print(f\"Confusion Matrix:\\n{final_confusion_matrix_lr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final SVM Model Results:\n",
      "Accuracy: 0.8126\n",
      "Precision: 0.7041\n",
      "Recall: 0.5040\n",
      "F1 Score: 0.5875\n",
      "Confusion Matrix:\n",
      "[[957  79]\n",
      " [185 188]]\n"
     ]
    }
   ],
   "source": [
    "# Train final SVM model with best parameters\n",
    "final_model_svm = SVC(**best_params_svm, random_state=42)\n",
    "final_model_svm.fit(X_train, y_train)\n",
    "y_pred_final_svm = final_model_svm.predict(X_test)\n",
    "\n",
    "# Evaluate final SVM model\n",
    "final_accuracy_svm = accuracy_score(y_test, y_pred_final_svm)\n",
    "final_precision_svm = precision_score(y_test, y_pred_final_svm)\n",
    "final_recall_svm = recall_score(y_test, y_pred_final_svm)\n",
    "final_f1_svm = f1_score(y_test, y_pred_final_svm)\n",
    "final_confusion_matrix_svm = confusion_matrix(y_test, y_pred_final_svm)\n",
    "\n",
    "print(\"\\nFinal SVM Model Results:\")\n",
    "print(f\"Accuracy: {final_accuracy_svm:.4f}\")\n",
    "print(f\"Precision: {final_precision_svm:.4f}\")\n",
    "print(f\"Recall: {final_recall_svm:.4f}\")\n",
    "print(f\"F1 Score: {final_f1_svm:.4f}\")\n",
    "print(f\"Confusion Matrix:\\n{final_confusion_matrix_svm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "After evaluating multiple models and tuning their hyperparameters, the Logistic Regression model was found to have the best performance with an accuracy of 82.04%, precision of 69.11%, recall of 58.18%, and F1 score of 63.17%. The model can now be used to predict customer churn with a reasonable degree of accuracy.\n",
    "\n",
    "In future work, we can further enhance model performance by exploring more advanced algorithms, using feature engineering techniques, and incorporating more data if available. Ensuring a balanced dataset through techniques like SMOTE (Synthetic Minority Over-sampling Technique) could also help improve model performance, especially recall.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
